{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gwj9IcVP-4bv"
      },
      "outputs": [],
      "source": [
        "# Importing packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload binary-coded matrix/interview data\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "DxR0NQ6E_A_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preview first 'n' data contents (Interview IDs in the first column and codes in the first row)\n",
        "df = pd.read_excel('S3. Binary_coded_matrix_data.xlsx')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "8FMIO1QZ_FjG",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract interview IDs and determine the number of interviews and codes\n",
        "interview_ids = df.iloc[:, 0].values\n",
        "total_interviews = len(interview_ids)\n",
        "total_codes = df.shape[1] - 1  #remove the first column since it contains interview IDs\n",
        "\n",
        "# Function to calculate the saturation curve\n",
        "def calculate_saturation_curve(interview_sequence):\n",
        "    discovered_codes = set()\n",
        "    saturation_percentages = []\n",
        "\n",
        "    for interview_id in interview_sequence:\n",
        "        codes = df[df.iloc[:, 0] == interview_id].iloc[:, 1:].values.flatten()  # gets codes for the current interview\n",
        "        discovered_codes.update(np.where(codes == 1)[0])   #updates the set of discovered codes\n",
        "        saturation = len(discovered_codes) / total_codes * 100   #calculate the percentage of codes discovered so far\n",
        "        saturation_percentages.append(saturation)\n",
        "\n",
        "    return saturation_percentages\n",
        "\n",
        "\n",
        "saturation_curve = calculate_saturation_curve(interview_ids)   #calculate the saturation curve using the original interview order\n",
        "\n",
        "#Function for finding the number of interviews needed to reach a saturation threshold\n",
        "def find_saturation_point(curve, threshold):\n",
        "    for index, value in enumerate(curve):\n",
        "        if value >= threshold:\n",
        "            return index + 1   # +1 because interview count is 1-based (counting starting at 1 instead of 0)\n",
        "    return None\n",
        "\n",
        "#Determine when 80% and 90% saturation is reached\n",
        "saturation_80 = find_saturation_point(saturation_curve, 80)\n",
        "saturation_90 = find_saturation_point(saturation_curve, 90)\n",
        "\n",
        "#Plot the saturation curve\n",
        "plt.figure(figsize=(12, 6))\n",
        "x_values = np.arange(1, len(saturation_curve) + 1)\n",
        "plt.plot(x_values, saturation_curve, color='black', label='New Codes')\n",
        "\n",
        "#Vertical lines for saturation thresholds if found\n",
        "if saturation_80 is not None:\n",
        "    plt.axvline(saturation_80, color='blue', linestyle='--', label='80% Saturation')\n",
        "if saturation_90 is not None:\n",
        "    plt.axvline(saturation_90, color='orange', linestyle='--', label='90% Saturation')\n",
        "\n",
        "#labels and legend\n",
        "plt.xlabel('Number of Interviews')\n",
        "plt.ylabel('Percentage of Codes Discovered')\n",
        "plt.title('Code Saturation Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#Print summary\n",
        "print(\"Summary Table:\")\n",
        "if saturation_80 is not None:\n",
        "    print(f\"Interviews needed to reach 80% saturation: {saturation_80}\")\n",
        "if saturation_90 is not None:\n",
        "    print(f\"Interviews needed to reach 90% saturation: {saturation_90}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Pw5RmZAajZUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to calculate the number of new codes discovered per interview\n",
        "\n",
        "def calculate_new_codes(dataframe, interview_sequence):\n",
        "    discovered_codes = set()\n",
        "    new_codes_per_interview = []\n",
        "\n",
        "    for interview_id in interview_sequence:\n",
        "        codes = dataframe[dataframe.iloc[:, 0] == interview_id].iloc[:, 1:].values.flatten() #get the codes for the current interview\n",
        "        current_codes = set(np.where(codes == 1)[0])\n",
        "\n",
        "        new_codes = current_codes - discovered_codes  #identify newly discovered codes\n",
        "        new_codes_per_interview.append(len(new_codes))\n",
        "\n",
        "        discovered_codes.update(current_codes)  #update the set of discovered codes\n",
        "\n",
        "    return new_codes_per_interview\n",
        "\n",
        "#Calculate new codes for the actual interview order\n",
        "actual_order = interview_ids\n",
        "actual_new_codes = calculate_new_codes(df, actual_order)\n",
        "\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "np.random.seed(122)\n",
        "\n",
        "\n",
        "#Calculate new codes for a random interview order\n",
        "random_order = np.random.permutation(interview_ids)\n",
        "random_new_codes = calculate_new_codes(df, random_order)\n",
        "\n",
        "#Set up x-axis positions for the bar chart\n",
        "x_positions = np.arange(total_interviews)  # 0-based indexing for plotting\n",
        "\n",
        "#Define bar width and offset for side-by-side bars and create the bar chart\n",
        "bar_width = 0.35\n",
        "offset = bar_width / 2\n",
        "\n",
        "plt.figure(figsize=(15, 7))\n",
        "\n",
        "#Plot for actual interview order\n",
        "plt.bar(x_positions - offset, actual_new_codes, bar_width, alpha=0.7, label='Actual Order', color='blue')\n",
        "\n",
        "#Plot for random interview order\n",
        "plt.bar(x_positions + offset, random_new_codes, bar_width, alpha=0.7, label='Random Order', color='grey')\n",
        "plt.xticks(x_positions, np.arange(1, total_interviews + 1))\n",
        "\n",
        "plt.xlabel('Interview Number')\n",
        "plt.ylabel('Number of New Codes')\n",
        "plt.title('New Codes Discovered per Interview')\n",
        "plt.legend()\n",
        "plt.grid(axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "total_unique_codes = (df.iloc[:, 1:] == 1).any(axis=0).sum()\n",
        "print(f\"Total number of unique codes: {total_unique_codes}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "eLdstKZhkkRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the number of iterations\n",
        "num_iterations = 10000\n",
        "\n",
        "#Extract interview IDs and determine dimensions (uncomment if sequential saturation curve has not been run)\n",
        "#interview_ids = df.iloc[:, 0].values\n",
        "#total_interviews = len(interview_ids)\n",
        "#total_codes = df.shape[1] - 1\n",
        "\n",
        "#Lists to store the number of interviews needed to reach 80% and 90% saturation\n",
        "saturation_80_list = []\n",
        "saturation_90_list = []\n",
        "\n",
        "#Run bootstrap iterations\n",
        "for _ in range(num_iterations):\n",
        "    sampled_ids = np.random.choice(interview_ids, total_interviews, replace=True)   #sample interviews with replacement\n",
        "    discovered_codes = set()\n",
        "    reached_80 = False\n",
        "    reached_90 = False\n",
        "\n",
        "    #Track saturation as interviews accumulate\n",
        "    for i, interview_id in enumerate(sampled_ids):\n",
        "        codes = df[df.iloc[:, 0] == interview_id].iloc[:, 1:].values.flatten()  #obtain codes for the current interview\n",
        "        discovered_codes.update(np.where(codes == 1)[0])\n",
        "        saturation_pct = len(discovered_codes) / total_codes * 100\n",
        "\n",
        "        #Record the first interview where 80% saturation is reached\n",
        "        if not reached_80 and saturation_pct >= 80:\n",
        "            saturation_80_list.append(i + 1)\n",
        "            reached_80 = True\n",
        "\n",
        "        # Record the first interview where 90% saturation is reached\n",
        "        if not reached_90 and saturation_pct >= 90:\n",
        "            saturation_90_list.append(i + 1)\n",
        "            reached_90 = True\n",
        "\n",
        "#Function to plot curves\n",
        "def plot_ecdf(data, label):\n",
        "    sorted_data = np.sort(data)\n",
        "    ecdf = np.arange(1, len(sorted_data) + 1) / len(sorted_data) * 100\n",
        "    plt.plot(sorted_data, ecdf, label=label, linewidth=2)\n",
        "\n",
        "#Plot curves for 80% and 90% saturation\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_ecdf(saturation_80_list, '80% Saturation')\n",
        "plot_ecdf(saturation_90_list, '90% Saturation')\n",
        "\n",
        "plt.xlabel(\"Number of Interviews\")\n",
        "plt.ylabel(\"Percentage of Bootstrap Samples\")\n",
        "plt.title(\"ECDF of Interviews Needed to Reach Code Saturation\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.ylim(0, 100)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#summary statistics\n",
        "def print_bounds(data, level):\n",
        "    data = np.array(data)\n",
        "    median = int(np.median(data))\n",
        "    p5 = int(np.percentile(data, 5))\n",
        "    p95 = int(np.percentile(data, 95))\n",
        "    print(f\"{level}% Saturation:\")\n",
        "    print(f\"  Median = {median}\")\n",
        "    print(f\"  5th Percentile = {p5}\")\n",
        "    print(f\"  95th Percentile = {p95}\\n\")\n",
        "\n",
        "#Print summary\n",
        "print_bounds(saturation_80_list, 80)\n",
        "print_bounds(saturation_90_list, 90)\n",
        "\n"
      ],
      "metadata": {
        "id": "Rn2VmLoDmiid"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
